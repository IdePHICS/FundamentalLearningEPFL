{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pEkeCuKvrwrR"
   },
   "source": [
    "# Part 1\n",
    "\n",
    "**What did we learn last week?**: We got a first look at PyTorch and trained a deep learning model with automatic differentiation.\n",
    "\n",
    "**What you will learn today**: We will take a closer look at Convolutional Neural Networks and understand why they are ubiquitously used. Then, we will look at the *correct* way of evaluating performance. Finally, we will explore some important hyperparameters/design decision for\n",
    "boosting performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OaFU7fiLrwrU"
   },
   "source": [
    "## Convolutional Neural Networks\n",
    "\n",
    "Great sources:\n",
    "- https://poloclub.github.io/cnn-explainer/\n",
    "- https://setosa.io/ev/image-kernels/\n",
    "\n",
    "![](https://poloclub.github.io/cnn-explainer/assets/figures/convlayer_detailedview_demo.gif)\n",
    "\n",
    "**Why convolutions and not fully-connected layers?** In the previous lab, we used a MultiLayer Perceptron (MLP) to perform classification on the MNIST dataset of handwritten digits. However, MLPs expect a vector as an input and, hence, our first step was to *flatten* the image; from an input of shape $(1, 28, 28)$ we got a vector of $1\\times28\\times28=784$ elements. Then, each layer of the MLP is fully connected, meaning that all $784$ elements are fed into each neuron of the next layer.\n",
    "\n",
    "Does this sound reasonable?\n",
    "\n",
    "No! First, by flattening we implicitly lose *local* information. Assume you look at pixel in location $(5,5)$, then the neighboring pixels $(4,5),(6,5), (5,4), (5,6),\\dots$ are important and must be \"somewhat similar\". Second, by using all elements of the previous layer. the top left and bottom right pixels are used in the same computation.\n",
    "\n",
    "Convolutional Neural Networks address these (and more) concerns and are suitable for the image domain. But, what are convolutions? We start with a small matrix of weights, e.g. $3\\times3$, which is called a kernel. The kernel is then slided over the 2d input and we perform elementwise multiplication with the values the kernel is currently on. The summation of the $3\\times3=9$ elements is the output for the pixel. Hence, the kernel performs a \"local\" computation. *Back in the day*, kernels were hand-designed to perform a specific operation. For example, the Sobel operator is used for edge-detection:\n",
    "\n",
    "$$\n",
    "\\mathbf{G}_x=\\left[\\begin{array}{ccc}\n",
    "+1 & 0 & -1 \\\\\n",
    "+2 & 0 & -2 \\\\\n",
    "+1 & 0 & -1\n",
    "\\end{array}\\right] * \\mathbf{A} \\quad \\text { and } \\quad \\mathbf{G}_y=\\left[\\begin{array}{ccc}\n",
    "+1 & +2 & +1 \\\\\n",
    "0 & 0 & 0 \\\\\n",
    "-1 & -2 & -1\n",
    "\\end{array}\\right] * \\mathbf{A}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{G}=\\sqrt{\\mathbf{G}_x^2+\\mathbf{G}_y^2}\n",
    "$$\n",
    "\n",
    "For example:\n",
    "\n",
    "![](https://miro.medium.com/max/640/1*m9XHMKQPY6mKYsaykuVAsw.webp)\n",
    "\n",
    "Creating filters for every different scenario requires domain knowledge and is cumbersome. (Convolutional) Neural Networks learn the values of these filters in an \"end-to-end\" manner!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/IdePHICS/FundamentalLearningEPFL.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/content/FundamentalLearningEPFL/TP10/')\n",
    "import training_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 422,
     "status": "ok",
     "timestamp": 1701184497103,
     "user": {
      "displayName": "Davide Ghio",
      "userId": "11962714808641352630"
     },
     "user_tz": -60
    },
    "id": "iO1w6XxLrwrU",
    "outputId": "3a08a9e8-4fe7-428e-a3dc-9f52f1351676"
   },
   "outputs": [],
   "source": [
    "import importlib, types\n",
    "imp = types.ModuleType(\"imp\")\n",
    "imp.reload = importlib.reload\n",
    "sys.modules[\"imp\"] = imp\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4476,
     "status": "ok",
     "timestamp": 1701184502232,
     "user": {
      "displayName": "Davide Ghio",
      "userId": "11962714808641352630"
     },
     "user_tz": -60
    },
    "id": "jeANxtrirwrV"
   },
   "outputs": [],
   "source": [
    "# import our \"local\" library of functions\n",
    "from training_utils import train_epoch, fit, predict, visualize_images, plot_loss\n",
    "\n",
    "# also import everything else that we need\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 366,
     "status": "ok",
     "timestamp": 1701184606611,
     "user": {
      "displayName": "Davide Ghio",
      "userId": "11962714808641352630"
     },
     "user_tz": -60
    },
    "id": "Z_XF2A2NrwrV",
    "outputId": "cfe19bdb-2d38-4659-97c5-15bed15125a6"
   },
   "outputs": [],
   "source": [
    "# define the hyperparameters\n",
    "BATCH_SIZE = 1024\n",
    "TEST_BATCH_SIZE = 1024\n",
    "LEARNING_RATE = 0.01\n",
    "\n",
    "# find out which device is available\n",
    "DEVICE = None\n",
    "if torch.cuda.is_available():\n",
    "    # Requires NVIDIA GPU with CUDA installed\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "elif torch.mps.is_available():\n",
    "    # Requires Apple computer with M1 or later chip\n",
    "    DEVICE = torch.device(\"mps\")\n",
    "else:\n",
    "    # Not recommended, because it's slow. Move to Google Colab!\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1049,
     "status": "ok",
     "timestamp": 1701184503279,
     "user": {
      "displayName": "Davide Ghio",
      "userId": "11962714808641352630"
     },
     "user_tz": -60
    },
    "id": "NHm83SQRrwrW",
    "outputId": "1a2558da-73a0-45bb-b53a-e31f410a1de5"
   },
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.ToTensor()\n",
    "\n",
    "# load the train dataset\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data/',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform)\n",
    "\n",
    "# load the test dataset\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data/',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=2)\n",
    "\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=TEST_BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 278
    },
    "executionInfo": {
     "elapsed": 769,
     "status": "ok",
     "timestamp": 1701184504045,
     "user": {
      "displayName": "Davide Ghio",
      "userId": "11962714808641352630"
     },
     "user_tz": -60
    },
    "id": "q89MeDxsrwrW",
    "outputId": "0e08bd9e-53be-4cc6-db7a-ab09da9e653f"
   },
   "outputs": [],
   "source": [
    "visualize_images(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1701184504549,
     "user": {
      "displayName": "Davide Ghio",
      "userId": "11962714808641352630"
     },
     "user_tz": -60
    },
    "id": "43PwB961rwrW"
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # We use a Sequential, i.e. the inputs passes through each of\n",
    "        # the modules below, one-by-one\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,\n",
    "                out_channels=16,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1,\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(\n",
    "                in_channels=16,\n",
    "                out_channels=32,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "\n",
    "        # fully connected layer, output 10 classes\n",
    "        self.out = nn.Linear(1568, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.size(0), -1) #reshape the tensor\n",
    "        x = self.out(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 74697,
     "status": "ok",
     "timestamp": 1701105460943,
     "user": {
      "displayName": "Davide Ghio",
      "userId": "11962714808641352630"
     },
     "user_tz": -60
    },
    "id": "Gf1_j24qrwrW",
    "outputId": "cf5e21f0-34d0-47a8-82cc-b22a67e47411"
   },
   "outputs": [],
   "source": [
    "# initialize model\n",
    "cnn = CNN().to(DEVICE)\n",
    "\n",
    "# define the optimizer\n",
    "optimizer = torch.optim.SGD(cnn.parameters(), lr=0.1)\n",
    "\n",
    "# train the CNN\n",
    "losses = fit(\n",
    "    model=cnn,\n",
    "    train_dataloader=train_dataloader,\n",
    "    optimizer=optimizer,\n",
    "    epochs=10,\n",
    "    device=DEVICE\n",
    ")\n",
    "\n",
    "predict(model=cnn, test_dataloader=test_dataloader, device=DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IxmTE0vzrwrW"
   },
   "source": [
    "## CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9711,
     "status": "ok",
     "timestamp": 1701184519284,
     "user": {
      "displayName": "Davide Ghio",
      "userId": "11962714808641352630"
     },
     "user_tz": -60
    },
    "id": "tJw3IVtWrwrX",
    "outputId": "6f5529c9-04ad-4e91-a26c-178fa7f18bf7"
   },
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.ToTensor()\n",
    "\n",
    "# load the train dataset\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data/',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform)\n",
    "\n",
    "# load the test dataset\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data/',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=2)\n",
    "\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=TEST_BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 277
    },
    "executionInfo": {
     "elapsed": 971,
     "status": "ok",
     "timestamp": 1701184520253,
     "user": {
      "displayName": "Davide Ghio",
      "userId": "11962714808641352630"
     },
     "user_tz": -60
    },
    "id": "K_XBTPrArwrX",
    "outputId": "e7e23fec-6ab3-4d87-c94d-1e344db38aaf"
   },
   "outputs": [],
   "source": [
    "visualize_images(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 75458,
     "status": "ok",
     "timestamp": 1701105559476,
     "user": {
      "displayName": "Davide Ghio",
      "userId": "11962714808641352630"
     },
     "user_tz": -60
    },
    "id": "hzWeU1u4rwrX",
    "outputId": "8264e592-699a-4936-dc40-ecddfa79f1aa"
   },
   "outputs": [],
   "source": [
    "class CifarCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # We use a Sequential, i.e. the inputs passes through each of\n",
    "        # the modules below, one-by-one\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=3, #COLORED IMAGES!\n",
    "                out_channels=16,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1,\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(\n",
    "                in_channels=16,\n",
    "                out_channels=32,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "\n",
    "        # fully connected layer, output 10 classes\n",
    "        self.out = nn.Linear(2048, 10) #Now is 32x32 images!\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "\n",
    "cnn_cifar = CifarCNN().to(DEVICE)\n",
    "\n",
    "# define the optimizer\n",
    "optimizer = torch.optim.SGD(cnn_cifar.parameters(), lr=0.1)\n",
    "\n",
    "\n",
    "# train the CNN\n",
    "losses = fit(\n",
    "    model=cnn_cifar,\n",
    "    train_dataloader=train_dataloader,\n",
    "    optimizer=optimizer,\n",
    "    epochs=10,\n",
    "    device=DEVICE\n",
    ")\n",
    "\n",
    "predict(model=cnn_cifar, test_dataloader=test_dataloader, device=DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qaDaK-jGrwrX"
   },
   "source": [
    "**Takeaways**: CIfar10 is a more complex dataset than MNIST; the images are larger and RGB, the model is larger and a simple training scheme returns very bad results! How can we change this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VWDYxnhxrwrX"
   },
   "source": [
    "## Validation set\n",
    "\n",
    "Before looking into tips and tricks for boosting the performance of a model, we need to establish a proper evaluation protocol. This is where the validation set comes in.\n",
    "\n",
    "In the real world, we do not have access to the test set, e.g., customer churning or self-driving cars. But, still, we need to evaluate the performance of our models on *unseen data*. The most common way is to split the training set into training+validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1701184520253,
     "user": {
      "displayName": "Davide Ghio",
      "userId": "11962714808641352630"
     },
     "user_tz": -60
    },
    "id": "g-ve1ySyrwrX",
    "outputId": "cb4c36bc-60bb-4ddf-cfad-27811a5cbd26"
   },
   "outputs": [],
   "source": [
    "# load the train dataset\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data/',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform)\n",
    "\n",
    "# load the test dataset\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data/',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform)\n",
    "\n",
    "print(train_dataset)\n",
    "\n",
    "# Split the dataset into 50k-10k samples for training-validation.\n",
    "from torch.utils.data import random_split\n",
    "train_dataset,  valid_dataset = random_split(\n",
    "    train_dataset,\n",
    "    lengths=[50000, 10000],\n",
    "    generator=torch.Generator().manual_seed(42) #use a generator to insure reproducibilty\n",
    ")\n",
    "\n",
    "# what is the type of the \"new\" training dataset?\n",
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1701184520253,
     "user": {
      "displayName": "Davide Ghio",
      "userId": "11962714808641352630"
     },
     "user_tz": -60
    },
    "id": "O6Sqa6nOrwrX"
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=2)\n",
    "\n",
    "valid_dataloader = DataLoader(\n",
    "    dataset=valid_dataset,\n",
    "    batch_size=TEST_BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=2)\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=TEST_BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ffXBm9KErwrY"
   },
   "source": [
    "Let's modify the fit function to also use a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "def fit(\n",
    "    model: nn.Module,\n",
    "    train_dataloader: DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    epochs: int,\n",
    "    device: torch.device,\n",
    "    valid_dataloader: Optional[DataLoader]=None):\n",
    "    '''\n",
    "    the fit method simply calls the train_epoch() method for a\n",
    "    specified number of epochs.\n",
    "    '''\n",
    "\n",
    "    # keep track of the losses in order to visualize them later\n",
    "    # Train for numerous epochs:\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    valid_accs = []\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = train_epoch(\n",
    "            model=model,\n",
    "            train_dataloader=train_dataloader,\n",
    "            optimizer=optimizer,\n",
    "            device=device\n",
    "        )\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        if valid_dataloader is not None:\n",
    "            valid_loss, valid_acc = predict(model, valid_dataloader, device, verbose=False)\n",
    "            valid_losses.append(valid_loss)\n",
    "            valid_accs.append(valid_acc)\n",
    "\n",
    "        if valid_dataloader is None:\n",
    "            print(f\"Epoch {epoch}: Train Loss={train_loss:.4f}\")\n",
    "        else:\n",
    "            print(f\"Epoch {epoch}: Train Loss={train_loss:.4f}, Validation Loss={valid_loss:.4f}, Validation acc={valid_acc:.4f}\")\n",
    "\n",
    "    return train_losses, valid_losses, valid_accs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I5D4skVXrwrY"
   },
   "source": [
    "## Importance of optimizer and learning rate\n",
    "\n",
    "So far in this lab, we have used the same learning rate and optimizer (vanilla SGD). However, the choice of optimizer and the corresponding hyperparameters play a crucial role in the end performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ULjqysLrwrY"
   },
   "source": [
    "### Learning rate\n",
    "**Question** Explore the exact same experiment as before BUT change the learning rate to $0.001$. How does this change affect performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nUTLSGAC6pmO"
   },
   "source": [
    "**Question** Now try with a higher learning rate ($\\eta\\geq0.5$), describe (qualitatively) what happens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AE-bh1Sox_Ve"
   },
   "source": [
    "### Optimizer\n",
    "\n",
    "In this lab we have used (mini-batch) Stochastic Gradient Descent or simply SGD. For simplicity we consider the case for only one sample. The update rule is the following:\n",
    "\n",
    "$$\n",
    "\\mathbf{w}^{(\\tau+1)} \\gets \\mathbf{w}^{(\\tau)} - \\eta\\nabla L\\left(\\mathbf{x}, y;\\mathbf{w}^{(\\tau)}\\right)\n",
    "$$\n",
    "\n",
    "How can we improve our algorithm and encourage faster convergence? Momentum can actually help. The idea is simple: we will use the update made on the previous step and incorporate it to our current update, giving momentum to our algorithm. The actual update rule is the following:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathbf{v}^{(\\tau+1)} &\\gets \\gamma\\mathbf{v}^{(\\tau)} + \\nabla L\\left(\\mathbf{x}, y;\\mathbf{w}^{(\\tau)}\\right)\n",
    "\\\\\n",
    "\\mathbf{w}^{(\\tau+1)} &\\gets \\mathbf{w}^{(\\tau)} - \\eta \\mathbf{v}^{(\\tau)}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Apart from making convergence faster, momentum has other benefits:\n",
    "* dampens oscillations\n",
    "* helps us navigate ravines around local optima [1]\n",
    "\n",
    "If you are more interested in the various optimizers take a look at reference [1].\n",
    "\n",
    "----\n",
    "[1] Ruder, S., 2016. An overview of gradient descent optimization algorithms. arXiv preprint arXiv:1609.04747.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "42jQ7lsJA55P"
   },
   "source": [
    "**Question** Implement momentum and compute the learning curve. How does this change affect performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7YwJlhKqrwrY"
   },
   "source": [
    "## Hyperparameters: Learning rate and batch size\n",
    "\n",
    "While intution can help us select the settings of an experiment, the choice becomes complicated when more and more hyperparameters need to be taken account. Just to name a few, we might want to select learning rate, momentum or optimizer, batch size, number of layers, width of layers etc\n",
    "\n",
    "Hence, we need a systematic way to approach this problem. The most simple way is to perform a grid search; define a list of choices for each hyperparameter and search over all combinations.\n",
    "\n",
    "\n",
    "**Question** Perform a grid search over the learning rate and batch size. What is the best combination? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oEQbGVkSrwrY"
   },
   "source": [
    "# Part 2\n",
    "\n",
    "On the previous part we implemented CNNs using the `PyTorch` library. Our experiments showed that for image classification a CNN architecture yields good results on MNIST and, depending on the complexity of the network you created, \"good\" results on CIFAR10. However, dealing with MNIST someone might have gotten the wrong impression: \"everythings works out-of-the-box or like magic in Deep Learning\". Reality is not so rosy and we must go to great lengths do replicate our success on MNIST for other datasets.\n",
    "\n",
    "In this part, we will explore common pitfalls as well as common tips and tricks to resolve them. These simple methods will provide superior performance and are very easy to incorporate in our pipeline.\n",
    "\n",
    "Specifically, we will talk about:\n",
    "- Batch Normalization\n",
    "- Learning rate scheduler\n",
    "- Residual Connections\n",
    "\n",
    "So... let's get started!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 249,
     "status": "ok",
     "timestamp": 1701184559109,
     "user": {
      "displayName": "Davide Ghio",
      "userId": "11962714808641352630"
     },
     "user_tz": -60
    },
    "id": "AV9mIlnlrwrY"
   },
   "outputs": [],
   "source": [
    "# first we load all the necessary libraries\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1388,
     "status": "ok",
     "timestamp": 1701184561484,
     "user": {
      "displayName": "Davide Ghio",
      "userId": "11962714808641352630"
     },
     "user_tz": -60
    },
    "id": "SLfg-INhrwrZ",
    "outputId": "0f9b2df4-4797-491b-90a4-fa40344ea536"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# load the train dataset\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data/',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform)\n",
    "\n",
    "# load the test dataset\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data/',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 324,
     "status": "ok",
     "timestamp": 1701184563243,
     "user": {
      "displayName": "Davide Ghio",
      "userId": "11962714808641352630"
     },
     "user_tz": -60
    },
    "id": "PfbQsRLTrwrg"
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=2)\n",
    "\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1177f6PHrwrg"
   },
   "source": [
    "## Batch normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dwJ3X53jrwrg"
   },
   "source": [
    "We want to learn fast and converge at the same time. If we use a small learning rate, we will converge but it will be too slow. On the other hand, if we use large learning rate, our training will become inconsistent and we will bounce all over the place and never converge. Additionaly, higher learning rates  cause exploding or vanishing gradients i.e. the phenomenon where the multiplication of gradients via the chain rule induces a compound effect on the lower layers, preventing them from learning.\n",
    "\n",
    "Can we have the best of both worlds? Enter **Batch Normalization**.\n",
    "\n",
    "1. What does BatchNorm aims to solve? We want to\n",
    "    * avoid unstable gradients,\n",
    "    * allow faster learning rates leading to faster convergence,\n",
    "    * reduce the effect of initialization.\n",
    "\n",
    "2. What does BatchNorm actually do?\n",
    "\n",
    "Suppose we are given values of $x$ over a mini-batch $B=\\{x_i\\}_{i=1}^m$. Our goal is to learn some parameters $\\gamma$ and $\\beta$ that perform the proper scaling.\n",
    "\n",
    "- First, we compute the mini-batch mean\n",
    "    $$\n",
    "    \\mu_{B}=\\frac{1}{m}\\sum_{i=1}^mx_i\n",
    "    $$\n",
    "and mini-batch variance\n",
    "    $$\n",
    "    \\sigma^2_{B}=\\frac{1}{m}\\sum_{i=1}^m (x_i-\\mu_{B})^2\n",
    "    $$\n",
    "- we use these quantities to normalize our input\n",
    "    $$\n",
    "    x_i\\leftarrow\\frac{x_i-\\mu_{B}}{\\sqrt{\\sigma^2_{B}+\\epsilon}}\n",
    "    $$\n",
    "- We scale, shift and return the output\n",
    "    $$\n",
    "    y_i=\\gamma x_i+\\beta\\equiv \\text{BN}_{\\gamma, \\beta}(x_i)\n",
    "    $$\n",
    "Essentially, for each mini-batch we normalize the inputs by subtracting their mean and dividing by their standard deviation (estimated based on the statistics of the current mini-batch)  \n",
    "\n",
    "\n",
    "3. Why does BatchNorm work?\n",
    "\n",
    "    * BatchNorm is widely used (e.g. the original paper [1] has over 50000 citations). However, the reasons of its success are not perfectly clear.\n",
    "    * The original authors claim that BatchNorm helps alleviate *Internal Covariate shift*, i.e. the phenomenon of shifting input distributions. Specifically, the input to each layer can be seen as a data distribution that the layer is trying to “learn”. The model, though, does not see the whole dataset but simply mini-batches. If this distribution stays consistent across batches, the layer can \"learn effectively\".  But, does this happen in practice?\n",
    "    * the reality is that different mini-batches have different statistics, e.g. mean, variance etc, making the input distribution to the layers jump around. In other words, the input distribuion shifts for every mini-batch. We are trying to learn a \"moving target\". What if we stabilize it?\n",
    "    * Batch normalization keeps the input normalized (duh!), preventing them from becoming too large or small and keeping the distribution consistent.\n",
    "    \n",
    "    * It also directly placates the exploding/vanishing gradient problem and  allows higher learning rates.\n",
    "\n",
    "    * However, other explanations have been proposed. [2] claims that BatchNorm \"makes the optimization landscape significantly smoother. This smoothness induces a more predictive and stable behavior of the gradients, allowing for faster training\".\n",
    "\n",
    "\n",
    "---\n",
    "[1] S. Ioffe and C. Szegedy, “Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift,” in Proceedings of the 32nd International Conference on Machine Learning, Jun. 2015, pp. 448–456. Accessed: Oct. 25, 2021. [Online]. Available: https://proceedings.mlr.press/v37/ioffe15.html\n",
    "\n",
    "[2] S. Santurkar, D. Tsipras, A. Ilyas, and A. Madry, “How Does Batch Normalization Help Optimization?,” in Advances in Neural Information Processing Systems, 2018, vol. 31. Accessed: Oct. 25, 2021. [Online]. Available: https://papers.nips.cc/paper/2018/hash/905056c1ac1dad141560467e0a99e1cf-Abstract.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nOvg2Ue2LXqp"
   },
   "source": [
    "Let's redo the previous cnn architecture with batch normalization. \n",
    "Observe where the batch normalization goes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNwithBN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # We use a Sequential, i.e. the inputs passes through each of\n",
    "        # the modules below, one-by-one\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=3,\n",
    "                out_channels=16,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1,\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(\n",
    "                in_channels=16,\n",
    "                out_channels=32,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "\n",
    "        # fully connected layer, output 10 classes\n",
    "        self.out = nn.Linear(2048, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn2 = CNNwithBN().to(DEVICE)\n",
    "optimizer = torch.optim.SGD(cnn2.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "train_losses, valid_losses, valid_accs = fit(\n",
    "        cnn2,\n",
    "        train_dataloader = train_dataloader,\n",
    "        optimizer = optimizer,\n",
    "        epochs = 30,\n",
    "        device = DEVICE\n",
    ")\n",
    "\n",
    "plot_loss(train_losses)\n",
    "\n",
    "predict(\n",
    "    cnn2,\n",
    "    test_dataloader = test_dataloader,\n",
    "    device = DEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LHp4U1BNrwrh"
   },
   "source": [
    "**Question** One of the benefits of Batch Norm is that it allows us to use higher learning rates. Adapt the code above to do so. Does the model learn faster?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c3kjx9C8rwrh"
   },
   "source": [
    "## Learning rate scheduler\n",
    "\n",
    "We have just seen that batch normalization allows, in this case, for a quicker improvement with a higher learning rate. Still, the loss plateaus quickly and we start seeing minimal improvement. This is often due to the optimization algorithm overshooting the gradient descent.\n",
    "\n",
    "Can we reduce the step size on the go? Yes! :smiley: This is what learning schedulers are for. The idea is simple: instead of a constant learning rate, we reduce it based on some conditions, or after a certain amount of steps.\n",
    "\n",
    "Two common schedulers are [`MultiStepLR`][MultiStepLR] and [`ReduceLROnPlateau`][ReduceLROnPlateau]. The first one, simply multiplies our learning rate `lr` by a constant factor $\\gamma < 1$ after some predefined number of steps. For instance, if the initial learning rate is `lr=1`, and we set $\\gamma=0.5$ for \"milestones\" of 20 and 50, then the optimizer is going to use `lr=1` for the first 20 epochs, then `lr=0.5` for the subsequent 30, and finally `lr=0.25` for all the remaining ones.\n",
    "\n",
    "`ReduceLROnPlateau` tracks a given metric, e.g. validation loss or accuracy, and reduces the learning rate if no improvement is seen after a predefined number of steps, called \"patience\".\n",
    "\n",
    "[MultiStepLR]: https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.MultiStepLR.html\n",
    "[ReduceLROnPlateau]: https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.ReduceLROnPlateau.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lbybWI1Orwrh"
   },
   "source": [
    "In the following cell, we augment the `fit` function from previous weeks (in `training_utils.py`) to accept a scheduler argument and use it while training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training_utils import train_epoch\n",
    "\n",
    "def fit_scheduler(\n",
    "    model: nn.Module,\n",
    "    train_dataloader: DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    epochs: int,\n",
    "    device: torch.device,\n",
    "    scheduler: Optional[torch.optim.lr_scheduler._LRScheduler] = None\n",
    "):\n",
    "    losses = []\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = train_epoch(\n",
    "            model=model,\n",
    "            train_dataloader=train_dataloader,\n",
    "            optimizer=optimizer,\n",
    "            device=device,\n",
    "        )\n",
    "        print(f\"Epoch {epoch}: Loss={running_loss}\")\n",
    "        losses.append(running_loss)\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Q80f4Y_rwrh"
   },
   "source": [
    "Now we train again the batch-norm-cnn, using the `MultiStepLR` scheduler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn2 = CNNwithBN().to(DEVICE)\n",
    "optimizer = torch.optim.SGD(cnn2.parameters(), lr=0.05, momentum=0.9)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
    "    optimizer,\n",
    "    milestones=[25, 30],\n",
    "    gamma=0.1,\n",
    ")\n",
    "\n",
    "\n",
    "losses =   fit_scheduler(\n",
    "        cnn2,\n",
    "        train_dataloader = train_dataloader,\n",
    "        optimizer = optimizer,\n",
    "        epochs = 35,\n",
    "        device = DEVICE,\n",
    "        scheduler=scheduler,\n",
    ")\n",
    "\n",
    "plot_loss(losses)\n",
    "\n",
    "predict(\n",
    "    cnn2,\n",
    "    test_dataloader = test_dataloader,\n",
    "    device = DEVICE\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PtiaTA3Crwrh"
   },
   "source": [
    "## Residual connections\n",
    "\n",
    "As neural networks go deeper, they are able to construct complex representations and yield superior performance. However, we cannot simply stack as many layers as we want to increase the depth.\n",
    "\n",
    "![caption](media/resnet-no-skip-horizontal.png)\n",
    "\n",
    "This is due to the **vanishing gradient** problem. Specifically, backpropagating the gradient to earlier layers involves repeated multiplication (with small values) rendering the gradient extremely small. This effectively means that as we go deeper, performance gets saturated. Instead of improved performance we even have degradation!\n",
    "\n",
    "How can we reconcile this tradeoff? On the one hand, we want to increase depth but on the other hand this hurts convergence.\n",
    "\n",
    "Enter **skip connections** [3]! The network of the previous figure now becomes the following:\n",
    "\n",
    "![caption](media/resnet-horizontal.png)\n",
    "\n",
    "Now, let's think why these skip connections work. First, they allow the gradient to flow via this shortcut connection, which helps mitigate the problem of vanishing gradient. Second, they allow the model to learn the identity function. In other words, this ensures that the higher layer will perform at least as good as the lower layer.\n",
    "\n",
    "---\n",
    "[3] K. He, X. Zhang, S. Ren, and J. Sun, “Deep Residual Learning for Image Recognition,” in 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Las Vegas, NV, USA, Jun. 2016, pp. 770–778. doi: 10.1109/CVPR.2016.90.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RenoOqUDrwrh"
   },
   "source": [
    "First, we build the network of the first image, i.e. with no skip connections. The Resnet depicted above is characterized by an interesting pattern. It consists of \"super-blocks\" (see the different colors) and each one consists of two blocks that start after one residual connection and finish just before one. Notice that each color is associated with a different number, i.e. 64, 128, 256, 512.\n",
    "\n",
    "We will build a `nn.Module` for each block and repeat it to create the super-blocks and by extension the whole architecture.\n",
    "\n",
    "The ResNet depicted above is meant to be used for `ImageNet`, a more complex dataset compared to `CIFAR10`. For computational considerations, we amend our implementation and make a simpler version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1701184583546,
     "user": {
      "displayName": "Davide Ghio",
      "userId": "11962714808641352630"
     },
     "user_tz": -60
    },
    "id": "K3IGC9Xmrwrh"
   },
   "outputs": [],
   "source": [
    "class NonResidualBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels = in_planes,\n",
    "            out_channels = planes,\n",
    "            kernel_size=3,\n",
    "            stride=stride,\n",
    "            padding=1,\n",
    "            bias=False)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            planes,\n",
    "            planes,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1,\n",
    "            bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1352306,
     "status": "ok",
     "timestamp": 1701185971305,
     "user": {
      "displayName": "Davide Ghio",
      "userId": "11962714808641352630"
     },
     "user_tz": -60
    },
    "id": "FwkEbqPBrwrh",
    "outputId": "95713224-d1c1-4d11-e8cb-c18a1641e354"
   },
   "outputs": [],
   "source": [
    "# initialize the model\n",
    "model = ResNet(block=NonResidualBlock, num_blocks=[2,2,2,2]).to(DEVICE)\n",
    "\n",
    "# define the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# train the ResNet\n",
    "\n",
    "train_losses, valid_losses, valid_accs =   fit(\n",
    "        model,\n",
    "        train_dataloader = train_dataloader,\n",
    "        optimizer = optimizer,\n",
    "        epochs = 35,\n",
    "        device = DEVICE\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_loss(train_losses)\n",
    "\n",
    "# predict with the trained model\n",
    "predict(\n",
    "    model,\n",
    "    test_dataloader = test_dataloader,\n",
    "    device = DEVICE\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluated part: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nam1MxdTrwrh"
   },
   "source": [
    "Now, we add skip connections. Notice that sometimes the skip connection cannot be simply an identity function, since the dimensions will not match. Identify the condition when this is necessary. In that case, the shortcut function should be a convolution followed by BatchNorm.\n",
    "\n",
    "**Question** Fill the code below and train the network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CorrectBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # YOUR CODE GOES HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the model\n",
    "model = ResNet(block=CorrectBlock, num_blocks=[2,2,2,2]).to(DEVICE)\n",
    "\n",
    "# define the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# train the ResNet\n",
    "plot_loss(\n",
    "    fit(\n",
    "        model,\n",
    "        train_dataloader = train_dataloader,\n",
    "        optimizer = optimizer,\n",
    "        epochs = 3,\n",
    "        device = DEVICE\n",
    "    )\n",
    ")\n",
    "\n",
    "# predict with the trained model\n",
    "predict(\n",
    "    model,\n",
    "    test_dataloader = test_dataloader,\n",
    "    device = DEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-VursWpErwri"
   },
   "source": [
    "**Question:** It looks like the model without the residual connections performs better (3-4%), but on a closer examination of the training curves the residual model achieves lower loss much faster and then plateaus. You might try to add a scheduler to boost the performance!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "foli25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
