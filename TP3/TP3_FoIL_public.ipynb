{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiE4Goe58ycm"
      },
      "source": [
        "# EE-411 Fundamentals of inference and learning, EPFL \n",
        "## Exercise Session 3: Classification using k-Nearest Neighbors\n",
        "\n",
        "In this third set of exercises we will start to see an application of supervised learning, introducing one of the simplest-to-implement supervised machine learning algorithm that can be used to solve both classification and regression problems: **k-Nearest Neighbors (KNN)**.\n",
        "\n",
        "**What you will learn today:** In this third session, we will construct the kNN algorithm by hand, explaining different ways in which you can compute the distance between elements of a matrix. We will compute the train error and the test error, and we will see how they behave as a function of the parameter $k$ or of the degrees of freedom $N/k$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GRwyNOsUQwjT"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "np.random.seed(1234)\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams[\"figure.figsize\"] = (9, 9)\n",
        "plt.rcParams[\"font.size\"] = 15"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBHvZXS_8yco"
      },
      "source": [
        "Let us first generate some synthetic data. We will assume that we **know** what is the probability distribution of our datapoints, pay attention that usually we do not know it! \n",
        "Our **Generative Model** will be a Gaussian mixture model (GMM): \n",
        "* Assume that centroids from class zero and one are geneterated Gaussianly as follows\n",
        " $${\\vec m}_k^{(0)} \\sim \\mathcal{N} (\\vec{\\mu} = [1,0] ; I_2) \\qquad {\\vec m}_k^{(1)} \\sim \\mathcal{N} (\\vec{\\mu} = [0,1] ; I_2) $$ \n",
        "* For each class, sample 10 different centroids ${\\vec m}_k$\n",
        "* Sample the actual data from $\\mathcal{N} ({\\vec m}_k, \\frac{1}{5} I_2)$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's sample the centroids and plot them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Samples 10 centroids for each class from two different bivariate Normal distributions\n",
        "centroids_per_class = 10\n",
        "\n",
        "class0_centroids = [1, 0] + np.random.randn(centroids_per_class, 2)\n",
        "class1_centroids = [0, 1] + np.random.randn(centroids_per_class, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot centroids\n",
        "plt.figure(figsize=((12,5)))\n",
        "plt.plot(class0_centroids[:, 0], class0_centroids[:, 1], \"o\", markersize=8)\n",
        "plt.plot(class1_centroids[:, 0], class1_centroids[:, 1], \"x\", markersize=8)\n",
        "plt.title(\"Centroids\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Once we have the centroids we can sample the actual data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "samples_per_class = 100\n",
        "\n",
        "# Sample actual data sampling from Normal distributions positioned around the centroids (Pick the centroid of the chosen class uniformly)\n",
        "class0_labels = np.random.randint(10, size = samples_per_class)\n",
        "class1_labels = np.random.randint(10, size = samples_per_class)\n",
        "\n",
        "class0_samples = class0_centroids[class0_labels, :] + np.sqrt(1. / 5) * np.random.randn(samples_per_class, 2)\n",
        "class1_samples = class1_centroids[class1_labels, :] + np.sqrt(1. / 5) * np.random.randn(samples_per_class, 2)\n",
        "\n",
        "# Plot data\n",
        "plt.figure(figsize=((12,5)))\n",
        "plt.plot(class0_samples[:, 0], class0_samples[:, 1], \"o\", markersize=8)\n",
        "plt.plot(class1_samples[:, 0], class1_samples[:, 1], \"x\", markersize=8)\n",
        "plt.title(\"Samples\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is the problem that we want to solve: we are given these points and we want to find a decision boundary that ensures good generalization.\n",
        "This is in general our goal: we want to be able to correctly classify new samples, never seen before, once they are given to us.\n",
        "\n",
        "Let us group the data in a nice way. For binary classification problems like this one, the way data is usually arranged is in\n",
        "\n",
        "- a matrix $X$ of size $N \\times P$, where $N$ is the number of samples and $P$ is the number of features (in our case $N = 200$ and $P = 2$); the nomenclature \"feature\" is not always clear but usually we mean with it the dimension of the space in which the datapoints leave.\n",
        "- a label vector $y \\in \\{0, 1\\}^N$ saying to which class each sample belongs to"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Let's use the stack function to build the feature matrix and vector of labels \n",
        "X = np.vstack((class0_samples, class1_samples))\n",
        "y = np.hstack((np.zeros(samples_per_class), np.ones(samples_per_class)))\n",
        "\n",
        "print(X)\n",
        "print(y)\n",
        "\n",
        "n_samples, n_features = np.shape(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next we compute the distance matrix, a $N \\times N$ matrix containing the distance from each sample to all others (do we really need to?)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_distances(X):\n",
        "    n_samples = len(X)\n",
        "    distances = np.zeros((n_samples, n_samples))\n",
        "    \n",
        "    # Here goes the algorithm\n",
        "    for i in range(n_samples):\n",
        "        for j in range(n_samples):\n",
        "            distances[i, j] = np.sqrt((X[i, 0] - X[j, 0]) ** 2 + (X[i, 1] - X[j, 1]) ** 2)\n",
        "    \n",
        "    return distances"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you know already Python, you can recognize that it is not an efficient implementation. \n",
        "\n",
        "We wanto to minimize *for* loops in Python! This is a general rule."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "distances = compute_distances(X)\n",
        "%timeit compute_distances(X)\n",
        "print(distances)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# We can vectorize it!\n",
        "distances = np.sqrt(np.sum((X[:, np.newaxis] - X) ** 2, 2))\n",
        "%timeit np.sqrt(np.sum((X[:, np.newaxis] - X) ** 2, 2))\n",
        "print(distances)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Or use something that someone already wrote in C\n",
        "from scipy.spatial.distance import cdist\n",
        "distances = cdist(X, X)\n",
        "%timeit cdist(X, X)\n",
        "print(distances)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using the distance matrix we can now write our algorithm!\n",
        "\n",
        "**Workflow**: \n",
        "* Write a function that compute the $k$-nearest neighbor estimate for each point in the training set.\n",
        "* Use this function to assign a class to each point by majority vote choosing a $k$ of your choice\n",
        "* Compute the *training error* \n",
        "\n",
        "\n",
        "**Tip**: look up for the `np.argpartition` function.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#  Nice shortcut for looking up to a function is to use **?np.argpartition**\n",
        "?np.argpartition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4dtEWXwzELn"
      },
      "source": [
        "Let's write down the function which compute the $k$-nearest neighbour for each datapoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def knn(X, y, k):\n",
        "    n_samples = len(y)\n",
        "    distances = cdist(X, X)\n",
        "    estimate = np.zeros(n_samples)\n",
        "    \n",
        "    # For each sample in the training set...\n",
        "    for i in range(n_samples):\n",
        "        # Look up k closest samples\n",
        "        nns = np.argpartition(distances[:, i], k)[:k]\n",
        "        \n",
        "        # Assign estimate as a majority vote\n",
        "        estimate[i] = int(sum(y[nns] == 1) > sum(y[nns] == 0))\n",
        "\n",
        "    return estimate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now compute the estimated labels for a given instance $(X,y)$ at a fixed $k$ (e.g. $k=10$).\n",
        "\n",
        "Once we have the estimated labels we are ready to compute the *training error*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "est_labels = knn(X, y, 10)\n",
        "print(est_labels)\n",
        "\n",
        "# Let us compute the training error\n",
        "train_error = np.mean(y != est_labels)\n",
        "print(train_error)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot data\n",
        "plt.figure(figsize=((12,5)))\n",
        "plt.plot(X[y == 0, 0], X[y == 0, 1], \"o\", markersize=8)\n",
        "plt.plot(X[y == 1, 0], X[y == 1, 1], \"x\", markersize=8)\n",
        "\n",
        "# Draw a red circle around misclassified samples\n",
        "errors = (y != est_labels)\n",
        "plt.Figure(figsize=((12,5)))\n",
        "plt.plot(X[errors, 0], X[errors, 1], \"o\", color=\"red\", markeredgewidth=3, markerfacecolor=\"white\", markersize=12, alpha=0.5)\n",
        "#plt.plot(X[errors, 0], X[errors, 1], \"o\", color=\"red\", mew=3, mfc=\"white\", ms=12, alpha=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As expected, mistakes happen in regions where the majority of points belong to the other class.\n",
        "\n",
        "But what happens when we try to classify points outside the training set? \n",
        "\n",
        "This step is called the **test step**. This is crucial and we must be very careful while doing this. There are a few different ways of assessing this. For instance, we could have used only part of our data in the training set (usually around 80%), and use the remaining to compute the so-called **test error**.Since in our case however the generative model is known, we might as well just get more samples from it.\n",
        "\n",
        "\n",
        "$\\color{darkred}{Caveat}$: Never use samples used in the training step to assess the test performance!\n",
        "\n",
        "Please pay attention to the previous lines because during the following lectures we will deal always with $\\color{blue}{training}$ and $\\color{green}{test}$ error. The difference between them is the same that we encounter when considering $\\color{green}{learning}$ and  $\\color{blue}{memorizing}$: good learning means low test error **NOT** low training error."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sample test data from the model\n",
        "testsamples_per_class = 10000\n",
        "\n",
        "class0_testlabels = np.random.randint(10, size = testsamples_per_class)\n",
        "class1_testlabels = np.random.randint(10, size = testsamples_per_class)\n",
        "class0_testsamples = class0_centroids[class0_testlabels, :] + np.sqrt(1. / 5) * np.random.randn(testsamples_per_class, 2)\n",
        "class1_testsamples = class1_centroids[class1_testlabels, :] + np.sqrt(1. / 5) * np.random.randn(testsamples_per_class, 2)\n",
        "\n",
        "X_test = np.vstack((class0_testsamples, class1_testsamples))\n",
        "y_test = np.hstack((np.zeros(testsamples_per_class), np.ones(testsamples_per_class)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot test data\n",
        "plt.figure(figsize=((12,5)))\n",
        "plt.plot(X_test[y_test == 0, 0], X_test[y_test == 0, 1], \"o\", ms=8)\n",
        "plt.plot(X_test[y_test == 1, 0], X_test[y_test == 1, 1], \"x\", ms=8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now need to write a function similar to `knn` that computes the estimates not for the points on the training set, but for points on a new *test* set.\n",
        "\n",
        "\n",
        "* Write down the function which compute the estimated labels for a point in the test set at fixed $k$, say $k=10$\n",
        "* Compute with this function the test error\n",
        "\n",
        "**Tip**: Only distance between test point and training samples matter! Remember the caveat! "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluated question"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Implement the function `knn_test` which computes the estimated labels for the test set at fixed $k$\n",
        "* Plot the test and training error as a function of $N/k$\n",
        "* Do you recognize what is going on? Have we seen this phenomena in the theoretical lectures? Discuss in groups and try to understand what is the **key** concept to grasp from this graph (which apply well beyond the specific case of $k$-nearest neighboour)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def knn_test(X_train, y_train, X_test, y_test, k):\n",
        "   ### To complete ###\n",
        "\n",
        "    return estimate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "est_testlabels = knn_test(X, y, X_test, y_test, 10)\n",
        "\n",
        "# Let us compute the test error, now\n",
        "print(f\"The test error is {np.mean(y_test != est_testlabels)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "293rurCrL9dE"
      },
      "source": [
        "Great! \n",
        "\n",
        "We computed the relevant quantities which allows us to understnad how the algorithm is performing in this learning task. \n",
        "\n",
        "Still something is not clear: **How do I choose $k$?**\n",
        "\n",
        "Indeed when using $k$-nearest neighbors we have to pick a value for $k$ -- it is not clear in principle how to do it! \n",
        "\n",
        "In order to understand this better, let us look at how the training and test errors behave as a function of $k$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convenience functions that compute the training and test errors, given training and test samples\n",
        "def compute_train_error(X, y, k=1):\n",
        "    y_hat = knn(X, y, k)\n",
        "    return np.mean(y != y_hat)\n",
        "    \n",
        "def compute_test_error(X_train, y_train, X_test, y_test, k=1):\n",
        "    y_hat = knn_test(X_train, y_train, X_test, y_test, k)\n",
        "    return np.mean(y_test != y_hat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 927
        },
        "id": "tJQR-sqY8ycz",
        "outputId": "c5ebb6ec-b75a-4841-c493-2b64065ec60a"
      },
      "outputs": [],
      "source": [
        "# Run functions for k belonging to a range of values\n",
        "ks = np.arange(1, 20)\n",
        "train_error = []\n",
        "test_error = []\n",
        "for (i, k) in enumerate(ks):\n",
        "    train_error.append(compute_train_error(X, y, k))\n",
        "    test_error.append(compute_test_error(X, y, X_test, y_test, k))\n",
        "    print(\"k = %d; train error = %g, test error = %g\" % (k, train_error[-1], test_error[-1]))\n",
        "\n",
        "# Plot results\n",
        "plt.plot(ks, train_error, label = \"train\")\n",
        "plt.plot(ks, test_error, label = \"test\")\n",
        "plt.legend()\n",
        "plt.xlabel(r\"$k$\")\n",
        "plt.ylabel(\"misclassification error\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1SjvcJL8ycz"
      },
      "source": [
        "It is instructive to use another quantity in the x axis instead of $k$: the number of **degrees of freedom** $N / k$. \n",
        "\n",
        "Indeed, the larger the $k$, the smaller the number of effective parameters -- think for instance of the $k = N$ limit, where everyone is assigned the same label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eg2qk8R4Bri3"
      },
      "outputs": [],
      "source": [
        "### Plot as a function of N/k ### "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QmITMyFnBrm1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the next lectures we will explore principled way to choose hyperparaemters of the model such as Cross-Validation etc. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3vhDq7sT964"
      },
      "source": [
        "## Bonus section ##\n",
        "\n",
        "What we have done so far is to give **estimation** of the class to which a datapoint should belong. In general we don't know where our data comes from (see later when we analyze MNIST dataset for example).\n",
        "\n",
        "Nonetheless we considered a very special case where we knew that the Generative Model was a Gaussian Mixture Model (GMM) around the sampled centroids.\n",
        "\n",
        " During theoretical classes we saw that in these cases the best thing I can do is to do Bayesian inference!\n",
        "\n",
        "Rephrasing mathematically what we have is: $$P(y = 0|x) \\propto P(x| y=0) = GMM(\\{m_i^{(0)}\\}_{i=1}^{10})  \\qquad P(y = 1|x) \\propto P(x| y=1) = GMM(\\{m_i^{(1)}\\}_{i=1}^{10}) $$\n",
        "\n",
        "\n",
        "Let's code toghether a function that assign estimates in a Bayesian way."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def BayesFunction(class0_centroids,class1_centroids,position):\n",
        " diff0 = class0_centroids - position ; diff1 = class1_centroids - position\n",
        " exponents0 = np.sum(diff0**2,axis=1) ; exponents1 = np.sum(diff1**2,axis=1)\n",
        " p0=sum(np.exp(-2.5*exponents0))\n",
        " p1=sum(np.exp(-2.5*exponents1))\n",
        " if p0>p1:\n",
        "  return 0\n",
        " else:\n",
        "  return 1\n",
        "\n",
        "def ComputeBayesError(class0_centroids,class1_centroids,label,pos):\n",
        " frac=0\n",
        " for i in range(max(pos.shape)):\n",
        "  pred = BayesFunction(class0_centroids,class1_centroids,pos[i])\n",
        "  if pred != label[i]:\n",
        "     frac=frac+1\n",
        " return frac/max(pos.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "- Compute the Bayesian error on the training and on the test set\n",
        "- Plot the Bayesian test error along with the curves of the previous exercise. How does it look like? What can you conclude?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_error_bayes = ComputeBayesError(class0_centroids, class1_centroids, y, X)\n",
        "test_error_bayes = ComputeBayesError(class0_centroids, class1_centroids, y_test, X_test)\n",
        "print(\"Bayes train error = %g, Bayes test error = %g\" % (train_error_bayes, test_error_bayes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        " # Plot error as a function of the degrees of freedom\n",
        "plt.plot(len(y) / np.array(ks), train_error, \"-o\", label = \"train\",c='blue')\n",
        "plt.plot(len(y) / np.array(ks), test_error, \"-o\", label = \"test\", c='orange')\n",
        "plt.axhline(test_error_bayes,linestyle='dashed', label='Bayes test',c='orange')\n",
        "plt.legend()\n",
        "plt.xlabel(r\"degrees of freedom $N / k$\")\n",
        "plt.ylabel(\"misclassification error\")\n",
        "#plt.ylim((0.025, 0.15))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
